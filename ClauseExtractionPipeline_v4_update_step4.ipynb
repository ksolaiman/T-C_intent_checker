{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7f4b9e",
   "metadata": {},
   "source": [
    "# Clause Extraction Pipeline v2.3\n",
    "Includes:\n",
    "- Bullet clause grouping\n",
    "- Referential clause flagging\n",
    "- Interactive user intent input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22478940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clause Extraction Pipeline - Step-by-Step Modules\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import PyPDF2\n",
    "import docx\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# --- Step 1: Clause Corpus Collection (Automated from Online Sources or Manual Upload) ---\n",
    "\n",
    "def fetch_online_tos(name: str) -> str:\n",
    "    \"\"\"Fetch raw text of Terms from a known URL for a brokerage or credit card.\"\"\"\n",
    "    urls = {\n",
    "        \"fidelity\": \"https://www.fidelity.com/bin-public/060_www_fidelity_com/documents/customer-service/customer-agreement.pdf\",\n",
    "        \"bilt\": \"https://www.wellsfargo.com/credit-cards/agreements/bilt-agreement/\",\n",
    "        \"schwab\": \"https://www.schwab.com/legal/schwab-one-account-agreement\",\n",
    "        \"amex\": \"https://www.americanexpress.com/en-us/legal/cardmember-agreements/\",\n",
    "    }\n",
    "    if name not in urls:\n",
    "        raise ValueError(\"Unsupported provider\")\n",
    "    response = requests.get(urls[name])\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def load_local_document(file_path: str) -> str:\n",
    "    \"\"\"Extract text from local PDF or DOCX document.\"\"\"\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = \"\n",
    "\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "        return text\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = docx.Document(file_path)\n",
    "        return \"\n",
    "\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only PDF and DOCX are allowed.\")\n",
    "\n",
    "# --- Step 2: Clause Segmentation and Preprocessing ---\n",
    "\n",
    "def segment_sentences(doc_text: str) -> List[str]:\n",
    "    return nltk.sent_tokenize(doc_text)\n",
    "\n",
    "def extract_candidate_clauses(sentences: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract clauses by grouping together dependent sentences.\n",
    "    If a sentence starts with a referential cue (e.g., \"This\", \"Such\", \"These\"), \n",
    "    it is merged with the previous sentence.\n",
    "    \"\"\"\n",
    "    clauses = []  # list of dicts with 'text', 'referential', 'bullet'\n",
    "    buffer = \"\"\n",
    "    for sentence in sentences:\n",
    "        sent = sentence.strip()\n",
    "        if not sent:\n",
    "            continue\n",
    "        is_referential = bool(re.match(r\"^(This|These|Such|It|They|Those)\b\", sent))\n",
    "        is_bullet = bool(re.match(r\"^[\\-\\*â€¢]\\s\", sent)) or sent.endswith(\":\")\n",
    "\n",
    "        if is_referential:\n",
    "            buffer += \" \" + sent\n",
    "        elif is_bullet:\n",
    "            buffer += \"\n",
    "\" + sent\n",
    "        else:\n",
    "            if buffer:\n",
    "                clauses.append({\"text\": buffer.strip(), \"referential\": is_referential, \"bullet\": is_bullet})\n",
    "            buffer = sent\n",
    "    if buffer:\n",
    "        clauses.append({\"text\": buffer.strip(), \"referential\": False, \"bullet\": False})\n",
    "    return clauses\n",
    "\n",
    "# --- Step 3: Clause Typing and Tag Suggestion ---\n",
    "\n",
    "LEGAL_KEYWORDS = [\"may not\", \"must\", \"require\", \"subject to\", \"prohibited\", \"not permitted\", \"unless\"]\n",
    "DOMAIN_KEYWORDS = [\"settlement\", \"donation\", \"crypto\", \"margin\", \"unsettled\", \"gambling\", \"recurring\"]\n",
    "\n",
    "TYPES = [\"prohibited\", \"conditionally allowed\", \"allowed\", \"ambiguous\"]\n",
    "\n",
    "def suggest_tags(clause: str) -> List[str]:\n",
    "    tags = [k for k in DOMAIN_KEYWORDS if k in clause.lower()]\n",
    "    return tags\n",
    "\n",
    "def get_embedding_tags(clause: str, tag_pool: List[str] = DOMAIN_KEYWORDS) -> List[str]:\n",
    "    clause_emb = model.encode(clause, convert_to_tensor=True)\n",
    "    tag_embs = model.encode(tag_pool, convert_to_tensor=True)\n",
    "    scores = util.pytorch_cos_sim(clause_emb, tag_embs)[0]\n",
    "    return [tag_pool[i] for i, score in enumerate(scores) if score.item() > 0.5]\n",
    "\n",
    "# --- Clause Scoring Heuristics ---\n",
    "\n",
    "def score_clause(entry: Dict) -> Dict:\n",
    "    clause = entry['text']\n",
    "    words = clause.split()\n",
    "    length_score = max(0, min(1, len(words)/100)) if len(words) >= 5 else 0\n",
    "    keyword_score = 1.0 if any(k in clause.lower() for k in LEGAL_KEYWORDS) else 0.0\n",
    "    punct_score = 1.0 if clause.strip().endswith(\".\") else 0.5\n",
    "    manual_tags = suggest_tags(clause)\n",
    "    embed_tags = get_embedding_tags(clause)\n",
    "    tag_score = 1.0 if manual_tags or embed_tags else 0.0\n",
    "    struct_score = 0.8  # Placeholder structural score\n",
    "    total_score = round((length_score + keyword_score + punct_score + tag_score + struct_score) / 5, 2)\n",
    "    review_flag = total_score < 0.7\n",
    "\n",
    "    return {\n",
    "        \"clause\": clause,\n",
    "        \"referential\": entry.get('referential', False),\n",
    "        \"bullet\": entry.get('bullet', False),\n",
    "        \"length_score\": round(length_score, 2),\n",
    "        \"keyword_score\": keyword_score,\n",
    "        \"punctuation_score\": punct_score,\n",
    "        \"domain_score\": tag_score,\n",
    "        \"structure_score\": struct_score,\n",
    "        \"quality_score\": total_score,\n",
    "        \"review_needed\": review_flag,\n",
    "        \"manual_tags\": manual_tags,\n",
    "        \"embed_tags\": embed_tags\n",
    "    }\n",
    "\n",
    "# --- Step 4: Intent Input Processing (Mocked) ---\n",
    "\n",
    "def normalize_intent(intent: str) -> str:\n",
    "    return intent.strip().lower()\n",
    "\n",
    "# --- Step 5: Semantic Matching ---\n",
    "\n",
    "def semantic_match(intent: str, clauses: List[str]) -> List[Dict]:\n",
    "    intent_vec = model.encode(intent, convert_to_tensor=True)\n",
    "    clause_vecs = model.encode(clauses, convert_to_tensor=True)\n",
    "    sims = util.pytorch_cos_sim(intent_vec, clause_vecs)[0]\n",
    "    return sorted([(clauses[i], sims[i].item()) for i in range(len(clauses))], key=lambda x: -x[1])\n",
    "\n",
    "# --- Step 6: Violation Detection and Feedback ---\n",
    "\n",
    "def detect_violation(intent: str, clause_db: pd.DataFrame, threshold: float = 0.5) -> Dict:\n",
    "    clause_texts = clause_db['clause'].tolist()\n",
    "    matches = semantic_match(intent, clause_texts)\n",
    "    if matches and matches[0][1] > threshold:\n",
    "        clause = matches[0][0]\n",
    "        row = clause_db[clause_db['clause'] == clause].iloc[0]\n",
    "        return {\n",
    "            \"violation\": True,\n",
    "            \"matched_clause\": clause,\n",
    "            \"score\": matches[0][1],\n",
    "            \"tags\": row.manual_tags + row.embed_tags,\n",
    "            \"explanation\": f\"Your action may conflict with the following clause: '{clause}'\"\n",
    "        }\n",
    "    return {\"violation\": False}\n",
    "\n",
    "# --- Pipeline Orchestration ---\n",
    "\n",
    "def process_documents(raw_docs: Dict[str, str]) -> pd.DataFrame:\n",
    "    all_clauses = []\n",
    "    for source, text in raw_docs.items():\n",
    "        sentences = segment_sentences(text)\n",
    "        candidates = extract_candidate_clauses(sentences)\n",
    "        for clause_entry in candidates:\n",
    "            scored = score_clause(clause_entry)\n",
    "            scored[\"source\"] = source\n",
    "            all_clauses.append(scored)\n",
    "    return pd.DataFrame(all_clauses)\n",
    "\n",
    "# --- Export to CSV for Manual Review ---\n",
    "\n",
    "def export_review_csv(df: pd.DataFrame, path: str = \"clauses_review.csv\"):\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "# --- Run the whole pipeline ---\n",
    "if __name__ == \"__main__\":\n",
    "    providers = [\"fidelity\", \"bilt\"]\n",
    "    docs = {p: fetch_online_tos(p) for p in providers}\n",
    "    df_clauses = process_documents(docs)\n",
    "    export_review_csv(df_clauses)\n",
    "    print(df_clauses.head())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
